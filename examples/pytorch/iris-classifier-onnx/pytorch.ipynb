{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iris_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiTxCwB7t6Ef",
        "colab_type": "text"
      },
      "source": [
        "# Training an Iris classifier using PyTorch\n",
        "In this notebook, we'll show how to train a classifier trained on the [iris data set](https://archive.ics.uci.edu/ml/datasets/iris) using PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6QdLAUpuW7r",
        "colab_type": "text"
      },
      "source": [
        "## Install Dependencies\n",
        "First, we'll install our dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQE5z_kHj9jV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install torch==1.2.* scikit-learn==0.21.* boto3==1.*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEVK-sLnumqn",
        "colab_type": "text"
      },
      "source": [
        "## Load the data\n",
        "We can use scikit-learn to load the Iris dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx9Xw0x0lfbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obGdgMm3urb2",
        "colab_type": "text"
      },
      "source": [
        "## Train the model\n",
        "We'll use PyTorch to define the neural net and train the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjYp8TaflhW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 100)\n",
        "        self.fc2 = nn.Linear(100, 100)\n",
        "        self.fc3 = nn.Linear(100, 3)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = F.relu(self.fc1(X))\n",
        "        X = self.fc2(X)\n",
        "        X = self.fc3(X)\n",
        "        X = self.softmax(X)\n",
        "        return X\n",
        "\n",
        "\n",
        "train_X = Variable(torch.Tensor(X_train).float())\n",
        "test_X = Variable(torch.Tensor(X_test).float())\n",
        "train_y = Variable(torch.Tensor(y_train).long())\n",
        "test_y = Variable(torch.Tensor(y_test).long())\n",
        "\n",
        "model = Net()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(1000):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(train_X)\n",
        "    loss = criterion(out, train_y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(\"number of epoch {} loss {}\".format(epoch, loss))\n",
        "\n",
        "predict_out = model(test_X)\n",
        "_, predict_y = torch.max(predict_out, 1)\n",
        "\n",
        "print(\"prediction accuracy {}\".format(accuracy_score(test_y.data, predict_y.data)))  # Accuracy should be > 90%"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hdwu-wzJvJLb",
        "colab_type": "text"
      },
      "source": [
        "## Export the model\n",
        "Now we can export the model in the ONNX format:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVgs2mkdllRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "placeholder = torch.randn(1, 4)\n",
        "torch.onnx.export(\n",
        "    model, placeholder, \"pytorch.onnx\", input_names=[\"input\"], output_names=[\"species\"]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipVlP4yPxFxw",
        "colab_type": "text"
      },
      "source": [
        "## Upload the model to AWS\n",
        "\n",
        "Cortex loads models from AWS, so we need to upload the exported model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IqsfyylxLhy",
        "colab_type": "text"
      },
      "source": [
        "Set these variables to configure your AWS credentials and model upload path:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc9LBH1uHT_h",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "AWS_ACCESS_KEY_ID = \"\" #@param {type:\"string\"}\n",
        "AWS_SECRET_ACCESS_KEY = \"\" #@param {type:\"string\"}\n",
        "S3_UPLOAD_PATH = \"s3://my-bucket/iris-classifier/pytorch.onnx\" #@param {type:\"string\"}\n",
        "\n",
        "import sys\n",
        "import re\n",
        "\n",
        "if AWS_ACCESS_KEY_ID == \"\":\n",
        "    print(\"\\033[91m{}\\033[00m\".format(\"ERROR: Please set AWS_ACCESS_KEY_ID\"), file=sys.stderr)\n",
        "\n",
        "elif AWS_SECRET_ACCESS_KEY == \"\":\n",
        "    print(\"\\033[91m{}\\033[00m\".format(\"ERROR: Please set AWS_SECRET_ACCESS_KEY\"), file=sys.stderr)\n",
        "\n",
        "else:\n",
        "    try:\n",
        "        bucket = re.search(\"s3://(.+?)/\", S3_UPLOAD_PATH).group(1)\n",
        "        key = re.search(\"s3://.+?/(.+)\", S3_UPLOAD_PATH).group(1)\n",
        "    except:\n",
        "        print(\"\\033[91m{}\\033[00m\".format(\"ERROR: Invalid s3 path (should be of the form s3://my-bucket/path/to/file)\"), file=sys.stderr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXeuZsaQxUc8",
        "colab_type": "text"
      },
      "source": [
        "Upload the model to S3:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLmnWTEVsu55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import boto3\n",
        "\n",
        "s3 = boto3.client(\"s3\", aws_access_key_id=AWS_ACCESS_KEY_ID, aws_secret_access_key=AWS_SECRET_ACCESS_KEY)\n",
        "print(\"Uploading {} ...\".format(S3_UPLOAD_PATH), end = '')\n",
        "s3.upload_file(\"pytorch.onnx\", bucket, key)\n",
        "print(\" âœ“\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR-mmcUzyCV3",
        "colab_type": "text"
      },
      "source": [
        "<!-- CORTEX_VERSION_MINOR -->\n",
        "That's it! See the [example on GitHub](https://github.com/cortexlabs/cortex/tree/master/examples/iris-classifier) for how to deploy the model as an API."
      ]
    }
  ]
}
