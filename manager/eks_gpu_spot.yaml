# Copyright 2019 Cortex Labs, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: $CORTEX_CLUSTER_NAME
  region: $CORTEX_REGION
  version: "1.14"

nodeGroups:
  - name: ng-cortex-operator
    instanceType: t3.medium
    minSize: 1
    maxSize: 2
    desiredCapacity: 1
    ami: auto
    iam:
      withAddonPolicies:
        autoScaler: true
    tags:
      k8s.io/cluster-autoscaler/enabled: 'true'
    kubeletExtraConfig:
      kubeReserved:
        cpu: 150m
        memory: 300Mi
        ephemeral-storage: 1Gi
      kubeReservedCgroup: /kube-reserved
      systemReserved:
        cpu: 150m
        memory: 300Mi
        ephemeral-storage: 1Gi
      evictionHard:
        memory.available:  200Mi
        nodefs.available: 5%

  - name: ng-cortex-worker
    instanceType: mixed
    minSize: $CORTEX_MIN_INSTANCES
    maxSize: $CORTEX_MAX_INSTANCES
    desiredCapacity: $CORTEX_DESIRED_INSTANCES
    ami: auto
    iam:
      withAddonPolicies:
        autoScaler: true
    instancesDistribution:
      onDemandPercentageAboveBaseCapacity: 0
      instanceTypes:
        - p3.2xlarge
        - p3.8xlarge
        - p3.16xlarge
        - p2.xlarge
        - p2.8xlarge
        - p2.16xlarge
      spotInstancePools: 5
    tags:
      k8s.io/cluster-autoscaler/enabled: 'true'
      k8s.io/cluster-autoscaler/node-template/label/nvidia.com/gpu: 'true'
      k8s.io/cluster-autoscaler/node-template/taint/dedicated: nvidia.com/gpu=true
      k8s.io/cluster-autoscaler/node-template/label/workload: 'true'
    labels:
      lifecycle: Ec2Spot
      workload: "true"
      nvidia.com/gpu: 'true'
    taints:
      nvidia.com/gpu: "true:NoSchedule"
      workload: "true:NoSchedule"
    kubeletExtraConfig:
      kubeReserved:
        cpu: 150m
        memory: 300Mi
        ephemeral-storage: 1Gi
      kubeReservedCgroup: /kube-reserved
      systemReserved:
        cpu: 150m
        memory: 300Mi
        ephemeral-storage: 1Gi
      evictionHard:
        memory.available: 200Mi
        nodefs.available: 5%

  - name: gpu-spot-ng-a
    ami: auto
    instanceType: mixed
    desiredCapacity: 0
    minSize: 0
    maxSize: 10
    volumeSize: 100
    volumeType: gp2
    volumeEncrypted: true
    iam:
      attachPolicyARNs:
        - arn:aws:iam::aws:policy/service-role/AmazonEC2RoleforSSM
        - arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy
        - arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy
        - arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly
      withAddonPolicies:
        autoScaler: true
        ebs: true
        fsx: true
        efs: true
        albIngress: true
        cloudWatch: true
    instancesDistribution:
      onDemandPercentageAboveBaseCapacity: 0
      instanceTypes:
        - p3.2xlarge
        - p3.8xlarge
        - p3.16xlarge
        - p2.xlarge
        - p2.8xlarge
        - p2.16xlarge
      spotInstancePools: 5
    tags:
      k8s.io/cluster-autoscaler/node-template/taint/dedicated: nvidia.com/gpu=true
      k8s.io/cluster-autoscaler/node-template/label/nvidia.com/gpu: 'true'
      k8s.io/cluster-autoscaler/enabled: 'true'
    labels:
      lifecycle: Ec2Spot
      nvidia.com/gpu: 'true'
      k8s.amazonaws.com/accelerator: nvidia-tesla
    taints:
      nvidia.com/gpu: "true:NoSchedule"
    privateNetworking: true
    availabilityZones: ["us-west-2a"]
